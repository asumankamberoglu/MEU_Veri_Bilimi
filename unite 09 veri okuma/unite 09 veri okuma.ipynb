{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python çalışma ortamına veri okuma yapmadan önce, çalışma klasörümüzde öncelikle hangi dosyaların bulunduğuna ilişkin fikrimizin olması gerekir. os modülünü yükleyerek aşağıdaki kodları çalıştırdığımızda, çalışma klasörümüzde yüklü olan dosyalar listelenecektir. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'cars_train_annos.mat', 'coor.csv', 'credit.txt', 'EmployeeData.json', 'istanbul_hastane.json', 'lorem_ipsum.txt', 'MERS_IGS.csv', 'mutluluk_indeksi.xlsx', 'netflix.csv', 'sample.json', 'sample.txt', 'SASVisualForecasting_sampledatasets.zip', 'tax.dta', 'tax.sas7bdat', 'titanic.csv', 'traffic_density_20200711.csv', 'traffic_density_202010.csv', 'unite 09 veri okuma.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "yuklu_dosyalar = os.listdir('.')\n",
    "print(yuklu_dosyalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Düz Dosyaları Okuma\n",
    "\n",
    ".txt ya da .csv uzantılı dosyalar düz dosyalardır. .txt dosyaları metin dosyalarıdır. .csv dosyaları ise (Comma Separated Values), virgül ile ayrılmış, satır ve sütunlardan oluşan değerleri barındıran düz dosya tipleridir. \n",
    "\n",
    "Çalışma klasörümüzde bulunan lorem_ipsum.txt adındaki dosyayı salt okunur olarak Python çalışma ortamımıza ekleyelim. Lorem Ipsum, dizgi ve baskı endüstrisinde kullanılan Latince mıgır metinlerdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bir dosya açalım: dosya\n",
    "dosya = open('lorem_ipsum.txt', \"r\") # Salt okunur olarak eklemek istediğimiz için \"r\" kullandık. \n",
    "\n",
    "# Dosyayı üzerine yazılabilir formatta açabilmek için \"w\" şeklinde bir yazım tercih etmemiz gerekir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc volutpat vestibulum turpis vitae eleifend. Nullam vitae sollicitudin erat, non interdum felis. Aenean fringilla nec orci eu eleifend. Suspendisse semper turpis nec libero finibus, eget viverra ante molestie. Proin quis pulvinar metus. Nunc tortor felis, faucibus ac purus eu, suscipit dictum dolor. Nullam vel mi sed nibh varius cursus.\n",
      "\n",
      "Phasellus aliquet nunc nec ex convallis tincidunt. Phasellus ac pretium massa. Aenean purus urna, egestas sit amet pharetra non, volutpat ut metus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi non mauris non mauris interdum eleifend. Cras ex purus, dignissim sit amet velit at, molestie scelerisque justo. Phasellus sit amet placerat lorem. Pellentesque sodales, lacus in cursus faucibus, nulla sem egestas nisl, sit amet molestie lorem nunc eget nibh. Vestibulum fringilla risus nec ipsum semper, fermentum facilisis eros aliquam. Nulla porttitor risus ut diam accumsan maximus at at sapien. Proin urna ante, tincidunt id turpis eu, venenatis auctor ipsum. Vivamus et orci elementum, faucibus orci id, malesuada justo.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dosyadaki metni ekrana yazdıralım.\n",
    "print(dosya.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Dosyanın açık mı kapalı mı olduğunu denetleyelim.\n",
    "print(dosya.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dosyamız açık olduğu için kapatalım.\n",
    "dosya.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Tekrar kontrol edelim.\n",
    "print(dosya.closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".csv uzantılı dosyaları (Comma Separated Values) listelerden oluşan verileri barındırmakta olan düz bir dosya türüdür. Genellikle farklı uygulamalar arasında veri değişimini sağlamak amacıyla sıklıkla kullanılır. Veriler; virgül, noktalı virgül, aralık ya da başka işaretler kullanılarak ayrılır (delimiter). .csv uzantılı dosyaları metin editörleri (notepad vb.) ya da hesap tablosu programları (excel vb.) ile okuyabilmek ya da düzenleyebilmek olanaklıdır. .csv dosyalarının ilk satırı (header), verinin içindeki sütunların isimlerini barındırır.\n",
    "\n",
    "NumPy kütüphanesi kullanarak düz dosyaları Python ortamına akratabilmekteyiz. Aşağıdaki örnekte, 1000 satırdan oluşan ve sadece enlem-boylam verilerini içeren bir .csv dosyasını açmaktayız. Bu dosyadaki veriler, virgül ile ayrıldığı için `delimiter=\",\"` ifadesini kullandık. Bu tarz gerçekçi ama uydurma veriler üretebilmek için https://www.mockaroo.com/ adresini kullanabilirsiniz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.1215276 -75.3587075]\n",
      " [  3.4802964  97.8120924]\n",
      " [  8.2301756 -80.5549561]\n",
      " ...\n",
      " [ 55.7213148  37.6243984]\n",
      " [ 27.569517  110.001922 ]\n",
      " [ 38.1788095  15.4976181]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dosya_ismi = \"coor.csv\"\n",
    "veri = np.loadtxt(dosya_ismi, delimiter = ',')\n",
    "print(veri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir sonraki örneğimizde kredi kartı numaralarını ve yıllık harcamalarını içeren iki sütuna sahip bir .txt dosyasını NumPy kütüphanesi yardımıyla okuyalım. .txt dosyasını okumak için NumPy kütüphanesindeki `.loadtxt()` yöntemini kullanacağınız. Parantez içinde dosya ismini girdikten sonra, bu dosyadaki ayracın nokta virgül olduğunu `delimiter = \";\"` ifadesi ile göstereceğiz. İlk satırı okumak istemediğimiz için `skiprow = 1` ifadesini kullanıyoruz. Sadece kredi kartı limitlerini gösteren ikinci sütunu (birinci indeksi) data dosyası içerisine dahil etmek istediğimiz için de, `usecols=[1]` ifadesini argüman olarak ekliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40017. 11854. 23624. 24944. 24996. 32537. 33251. 12867.  8936. 32053.\n",
      " 37373. 27219. 44527.  8242. 34053.  9322. 11661. 28221.  6211. 26027.\n",
      " 14473. 10654. 13069. 25816. 15610. 34821. 40970. 28233. 13378. 37949.\n",
      " 31140. 25712. 39802. 36141. 43455. 13971. 40399. 34560. 37649. 13915.\n",
      " 26944. 18319. 24656. 15668. 14886. 30706. 44958. 48397. 30186. 43141.\n",
      " 25188. 26508.  9025. 25843. 43032.  8230. 46102. 11300. 17730. 26016.\n",
      " 30092.  5999. 48292. 30295. 25528. 30809. 36954. 35716. 17544. 28282.\n",
      " 28464.  9946.  7287. 49619. 42702. 14838. 40901. 32313. 11183. 42414.\n",
      " 22721. 17835. 34900. 28810. 38037. 30236. 33060.  6652. 30364. 24732.\n",
      " 18577. 49337. 16455. 35248. 39711. 23480. 25204. 31865. 28664.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dosya ismini belirleyelim: dosya\n",
    "dosya = 'credit.txt'\n",
    "\n",
    "# Veri olarak yükleme: data\n",
    "data = np.loadtxt(dosya, delimiter=';', skiprows=1, usecols=[1])\n",
    "\n",
    "# Ekrana verelim.\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çoğunlukla farklı veri tiplerinden oluşan veri setleri üzerine çalışırız. Bir sütun metinlerden oluşurken, diğer bir sütun ondalık sayılardan oluşabilir. np.loadtxt() fonksiyonu, metin harici veri tiplerini yüklemekte başarısız olacaktır. Farklı veri tiplerini yönetebilmek için `np.genfromtxt()` fonksiyonu kullanılabilir. Veri tipini özel olarak belirtmezsek `(dtype = None)`, bu fonksiyon otomatik olarak sütunların hangi veri tipini içerdiğini bulacaktır. Çalışma klasörümüzde bulunan ve Titanik gemisi yolcularına ilişkin verileri barındıran titanic.csv dosyasını yüklemeye çalışalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[( 1, 0, 3, b'male', 22., 1, 0, b'A/5 21171',  7.25  , b'', b'S')\n",
      " ( 2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C')\n",
      " ( 3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282',  7.925 , b'', b'S')\n",
      " ( 4, 1, 1, b'female', 35., 1, 0, b'113803', 53.1   , b'C123', b'S')\n",
      " ( 5, 0, 3, b'male', 35., 0, 0, b'373450',  8.05  , b'', b'S')\n",
      " ( 6, 0, 3, b'male', nan, 0, 0, b'330877',  8.4583, b'', b'Q')\n",
      " ( 7, 0, 1, b'male', 54., 0, 0, b'17463', 51.8625, b'E46', b'S')\n",
      " ( 8, 0, 3, b'male',  2., 3, 1, b'349909', 21.075 , b'', b'S')\n",
      " ( 9, 1, 3, b'female', 27., 0, 2, b'347742', 11.1333, b'', b'S')\n",
      " (10, 1, 2, b'female', 14., 1, 0, b'237736', 30.0708, b'', b'C')]\n",
      "(891,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
    "print(data[0:10]) # Verinin ilk on sütunu ekrana verelim.\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.genfromtxt()` fonksiyonunda kullanılan ilk argüman dosya ismini belirtmektedir. İkinci argüman ise ayraç olan virgülü belirttiğimiz `delimiter` parametresidir. Üçüncü  `names` argümanı ise, dosyanın bir başlık satırı (header) içerdiğini belirtmek için kullanılmaktadır. Dosyamız bir header içerdiği için True parametresi kullanılmıştır. Dosyamızın boyutunu sorguladığımızda sadece 891 satırdan oluştuğunu görmekteyiz. Oysa ki bu dosya 891 satır, 11 sütundan oluşmaktadır. Bunun NumPy dizilerinin aynı tipte verileri barındırması zorunda olmasıdır. Dolayısıyla `np.genfromtxt()` fonksiyonu ile yüklenen dosyamız, her bir satırın bir dizi olduğu tek boyutlu bir liste olarak karşımıza çıkmaktadır. \n",
    "\n",
    "`np.genfromtxt()` fonksiyonuna alternatif olarak `np.recfromcsv()` fonksiyonu bulunmaktadır. İki fonksiyon da aynı davranış biçimine sahip olsa da, `np.recfromcsv()` fonksiyonunun sabit veri tipi None olmaktadır (dtype = None). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[( 1, 0, 3, b'male', 22., 1, 0, b'A/5 21171',  7.25  , b'', b'S')\n",
      " ( 2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C')\n",
      " ( 3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282',  7.925 , b'', b'S')\n",
      " ( 4, 1, 1, b'female', 35., 1, 0, b'113803', 53.1   , b'C123', b'S')\n",
      " ( 5, 0, 3, b'male', 35., 0, 0, b'373450',  8.05  , b'', b'S')\n",
      " ( 6, 0, 3, b'male', nan, 0, 0, b'330877',  8.4583, b'', b'Q')\n",
      " ( 7, 0, 1, b'male', 54., 0, 0, b'17463', 51.8625, b'E46', b'S')\n",
      " ( 8, 0, 3, b'male',  2., 3, 1, b'349909', 21.075 , b'', b'S')\n",
      " ( 9, 1, 3, b'female', 27., 0, 2, b'347742', 11.1333, b'', b'S')\n",
      " (10, 1, 2, b'female', 14., 1, 0, b'237736', 30.0708, b'', b'C')]\n",
      "(891,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:2372: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Dosya ismini belirleyelim: \n",
    "dosya = 'titanic.csv'\n",
    "\n",
    "# np.recfromcsv() dosyasını kullanarak verimizi yükleyelim.\n",
    "data = np.recfromcsv(dosya)\n",
    "\n",
    "# data verisinin ilk 10 elemanını ekrana verelim.\n",
    "print(data[:10])\n",
    "\n",
    "# data verisinin boyutunu inceleyelim.\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu şekilde bir listelerden ya da dizilerden oluşan liste kullanımı, veri bilimi açısından çeşitli eksiklikler barındırmaktadır. Bir veri bilimci, aşağıdaki özelliklere sahip veriler üzerinde çalışmayı her zaman tercih eder:\n",
    "\n",
    "1) İki boyutlu ve anlamlı bir şekilde etiketlenmiş veriler (Hangi sütunun ya da satırın neyi ifade ettiği bilinmeli).\n",
    "\n",
    "2) Sütunlarda genellikle farklı tiplerde veriler bulunmalı.\n",
    "\n",
    "3) Veriler birleştirilebilir, dilimlenebilir, gruplanabilir, değiştirilebilir olmalı.\n",
    "\n",
    "4) Üzerinde istatistiki analizler yapılabilmeli.\n",
    "\n",
    "5) Zaman serileri olarak çalışabilmeli.\n",
    "\n",
    "Tüm bu gereksinimleri karşılayabilmek için veri çerçeveleri (DataFrame) ve bunları yönetebileceğimiz pandas kütüphanesini kullanmak daha uygun olacaktır. Bir veri çerçevesi, farklı veri tiplerindeki veri değerlerini içeren, sıralı sütunlardan oluşan ve iki indeksli (hem satırlar hem sütunlar için indekslenmiş) veri yapılarıdır.\n",
    "\n",
    "İlk satırı sütün isimlerinden oluşan bir .csv dosyasını (bu örnekte de Titanik veri setini kullanalım) pandas kütüphanesi ile yüklemek için önce bu kütüphaneyi yüklemek gerekir. Aşağıdaki kodlar yardımıyla bu veri çerçevesini okuyalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
      "0            1         0       3    male  22.0      1      0   \n",
      "1            2         1       1  female  38.0      1      0   \n",
      "2            3         1       3  female  26.0      0      0   \n",
      "3            4         1       1  female  35.0      1      0   \n",
      "4            5         0       3    male  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        S  \n",
      "1          PC 17599  71.2833   C85        C  \n",
      "2  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3            113803  53.1000  C123        S  \n",
      "4            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# pandas kütüphanesini yükleyelim. pd olarak kısaltalım.\n",
    "import pandas as pd\n",
    "\n",
    "# dosya ismini atayalım.\n",
    "dosya1 = 'titanic.csv'\n",
    "\n",
    "# Veri çerçevesini (DataFrame) oluşturalım. pd.read_csv(dosya) yöntemi ile csv dosyaları okunur.\n",
    "df_titanic = pd.read_csv(dosya1)\n",
    "\n",
    "# Veri çerçevesinin ilk beş satırını .head() yöntemi ile ekrana verelim\n",
    "print(df_titanic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aynı işlemi Netflix'te gösterimde olan yapımları içeren veri seti üzerinde de gerçekleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id      tur                                   baslik  \\\n",
      "0  81145628    Movie  Norm of the North: King Sized Adventure   \n",
      "1  80117401    Movie               Jandino: Whatever it Takes   \n",
      "2  70234439  TV Show                       Transformers Prime   \n",
      "3  80058654  TV Show         Transformers: Robots in Disguise   \n",
      "4  80125979    Movie                             #realityhigh   \n",
      "\n",
      "                   yonetmen  \\\n",
      "0  Richard Finn, Tim Maltby   \n",
      "1                       NaN   \n",
      "2                       NaN   \n",
      "3                       NaN   \n",
      "4          Fernando Lebrija   \n",
      "\n",
      "                                                cast  \\\n",
      "0  Alan Marriott, Andrew Toth, Brian Dobson, Cole...   \n",
      "1                                   Jandino Asporaat   \n",
      "2  Peter Cullen, Sumalee Montano, Frank Welker, J...   \n",
      "3  Will Friedle, Darren Criss, Constance Zimmer, ...   \n",
      "4  Nesta Cooper, Kate Walsh, John Michael Higgins...   \n",
      "\n",
      "                                       ulke     eklenme_tarihi  \\\n",
      "0  United States, India, South Korea, China  September 9, 2019   \n",
      "1                            United Kingdom  September 9, 2016   \n",
      "2                             United States  September 8, 2018   \n",
      "3                             United States  September 8, 2018   \n",
      "4                             United States  September 8, 2017   \n",
      "\n",
      "   gosterim_tarihi   reyting      sure                          listelenme  \\\n",
      "0             2019     TV-PG    90 min  Children & Family Movies, Comedies   \n",
      "1             2016     TV-MA    94 min                     Stand-Up Comedy   \n",
      "2             2013  TV-Y7-FV  1 Season                            Kids' TV   \n",
      "3             2016     TV-Y7  1 Season                            Kids' TV   \n",
      "4             2017     TV-14    99 min                            Comedies   \n",
      "\n",
      "                                            aciklama  \n",
      "0  Before planning an awesome wedding for his gra...  \n",
      "1  Jandino Asporaat riffs on the challenges of ra...  \n",
      "2  With the help of three human allies, the Autob...  \n",
      "3  When a prison ship crash unleashes hundreds of...  \n",
      "4  When nerdy high schooler Dani finally attracts...  \n"
     ]
    }
   ],
   "source": [
    "# pandas kütüphanesini yükleyelim. pd olarak kısaltalım.\n",
    "import pandas as pd\n",
    "\n",
    "# dosya ismini atayalım.\n",
    "dosya2 = 'netflix.csv'\n",
    "\n",
    "# Veri çerçevesini (DataFrame) oluşturalım. pd.read_csv(dosya) yöntemi ile csv dosyaları okunur.\n",
    "df_netflix = pd.read_csv(dosya2)\n",
    "\n",
    "# Veri çerçevesinin ilk beş satırını .head() yöntemi ile ekrana verelim\n",
    "print(df_netflix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas ile oluşturulan veri çerçevelerini NumPy dizisine dönüştürmek de olanaklıdır. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id' 'tur' 'baslik' 'yonetmen' 'cast' 'ulke' 'eklenme_tarihi'\n",
      "  'gosterim_tarihi' 'reyting' 'sure' 'listelenme' 'aciklama']\n",
      " ['81145628' 'Movie' 'Norm of the North: King Sized Adventure'\n",
      "  'Richard Finn, Tim Maltby'\n",
      "  'Alan Marriott, Andrew Toth, Brian Dobson, Cole Howard, Jennifer Cameron, Jonathan Holmes, Lee Tockar, Lisa Durupt, Maya Kay, Michael Dobson'\n",
      "  'United States, India, South Korea, China' 'September 9, 2019' '2019'\n",
      "  'TV-PG' '90 min' 'Children & Family Movies, Comedies'\n",
      "  'Before planning an awesome wedding for his grandfather, a polar bear king must take back a stolen artifact from an evil archaeologist first.']\n",
      " ['80117401' 'Movie' 'Jandino: Whatever it Takes' nan 'Jandino Asporaat'\n",
      "  'United Kingdom' 'September 9, 2016' '2016' 'TV-MA' '94 min'\n",
      "  'Stand-Up Comedy'\n",
      "  'Jandino Asporaat riffs on the challenges of raising kids and serenades the audience with a rousing rendition of \"Sex on Fire\" in his comedy show.']\n",
      " ['70234439' 'TV Show' 'Transformers Prime' nan\n",
      "  'Peter Cullen, Sumalee Montano, Frank Welker, Jeffrey Combs, Kevin Michael Richardson, Tania Gunadi, Josh Keaton, Steve Blum, Andy Pessoa, Ernie Hudson, Daran Norris, Will Friedle'\n",
      "  'United States' 'September 8, 2018' '2013' 'TV-Y7-FV' '1 Season'\n",
      "  \"Kids' TV\"\n",
      "  'With the help of three human allies, the Autobots once again protect Earth from the onslaught of the Decepticons and their leader, Megatron.']\n",
      " ['80058654' 'TV Show' 'Transformers: Robots in Disguise' nan\n",
      "  'Will Friedle, Darren Criss, Constance Zimmer, Khary Payton, Mitchell Whitfield, Stuart Allan, Ted McGinley, Peter Cullen'\n",
      "  'United States' 'September 8, 2018' '2016' 'TV-Y7' '1 Season'\n",
      "  \"Kids' TV\"\n",
      "  'When a prison ship crash unleashes hundreds of Decepticons on Earth, Bumblebee leads a new Autobot force to protect humankind.']]\n"
     ]
    }
   ],
   "source": [
    "# Dosyamızın ismini belirleyelim. \n",
    "dosya3 = 'netflix.csv'\n",
    "\n",
    "# veri dosyası adında olarak yükleyelim. Verinin sadece ilk beş satırını alsın ve başlık satırı olmasın.\n",
    "veri = pd.read_csv(dosya3,nrows = 5, header = None)\n",
    "\n",
    "# Bu veri çerçevesinden bir NumPy dizisi oluşturalım. np.array() fonksiyonu bu amaç için kullanılmaktadır.\n",
    "veri_dizisi = np.array(veri)\n",
    "\n",
    "# veri_dizisinin veri türünü ekrana verelim. \n",
    "print(type(veri_dizisi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Excel Dosyalarını Okuma\n",
    "\n",
    "Veri bilimi ile uğraşan herkes, Excel hesap tabloları üzerine çalışmak zorundadır. Dünyada halen Excel formatında (.xls ya da .xlsx) veri setleri kullanılmakta ve dağıtılmaktadır. pandas kütüphanesi ile Excel dosyalarını çalışma ortamına yüklemek mümkündür. Bunun için `pd.ExcelFile()` fonksiyonu kullanılır. Dünya Mutluluk Raporu'nun 2019 verilerini barındıran Excel dosyasını (mutluluk_indeksi.xlsx) kullanalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019', '2018']\n",
      "<class 'pandas.io.excel._base.ExcelFile'>\n"
     ]
    }
   ],
   "source": [
    "# pandas kütüphanesini yükleyelim.\n",
    "import pandas as pd\n",
    "\n",
    "# Dosya ismini belirleyelim.\n",
    "dosya = 'mutluluk_indeksi.xlsx'\n",
    "\n",
    "# Excel dosyasını yükleyerek xl veri dosyasını oluşturalım.\n",
    "xl = pd.ExcelFile(dosya)\n",
    "\n",
    "# Excel dosyası içinde kayıtlı olan hesap tablolarını (ayrı sekmeler halinde saklanır) ekrana verelim.\n",
    "print(xl.sheet_names)\n",
    "print(type(xl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dosyada ülkelerin mutluluk indeksi verileri hem 2019 hem de 2018 yılları için ayrı ayrı hesap tablosu sekmesinde saklanmaktadır. Bu her iki hesap tablosu için ayrı veri çerçeveleri oluşturabiliriz. Bunun için `.parse()` yöntemi kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Overall rank Country or region  Score  GDP per capita  Social support  \\\n",
      "0             1           Finland   7769          1340.0          1587.0   \n",
      "1             2           Denmark   7600          1383.0          1573.0   \n",
      "2             3            Norway   7554          1488.0          1582.0   \n",
      "3             4           Iceland   7494          1380.0          1624.0   \n",
      "4             5       Netherlands   7488          1396.0          1522.0   \n",
      "\n",
      "   Healthy life expectancy  Freedom to make life choices  Generosity  \\\n",
      "0                    0.986                         0.596       0.153   \n",
      "1                    0.996                         0.592       0.252   \n",
      "2                 1028.000                         0.603       0.271   \n",
      "3                 1026.000                         0.591       0.354   \n",
      "4                    0.999                         0.557       0.322   \n",
      "\n",
      "   Perceptions of corruption  \n",
      "0                      0.393  \n",
      "1                      0.410  \n",
      "2                      0.341  \n",
      "3                      0.118  \n",
      "4                      0.298  \n"
     ]
    }
   ],
   "source": [
    "df1 = xl.parse('2019')\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.parse()` yönteminin içine hesap tablosunun ismini yazabileceğimiz gibi sıra numarasını (indeksini) de yazabiliriz. 2018 yılı için deneyelim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Overall rank Country or region  Score  GDP per capita  Social support  \\\n",
      "0             1           Finland   7632          1305.0          1592.0   \n",
      "1             2            Norway   7594          1456.0          1582.0   \n",
      "2             3           Denmark   7555          1351.0          1590.0   \n",
      "3             4           Iceland   7495          1343.0          1644.0   \n",
      "4             5       Switzerland   7487          1420.0          1549.0   \n",
      "\n",
      "   Healthy life expectancy  Freedom to make life choices  Generosity  \\\n",
      "0                    0.874                         0.681       0.202   \n",
      "1                    0.861                         0.686       0.286   \n",
      "2                    0.868                         0.683       0.284   \n",
      "3                    0.914                         0.677       0.353   \n",
      "4                    0.927                         0.660       0.256   \n",
      "\n",
      "   Perceptions of corruption  \n",
      "0                      0.393  \n",
      "1                      0.340  \n",
      "2                      0.408  \n",
      "3                      0.138  \n",
      "4                      0.357  \n"
     ]
    }
   ],
   "source": [
    "df2 = xl.parse(1)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi ilk hesap tablosunu, `.parse()` yöntemi ile veri çerçevesi haline getirelim. İlk satırı atlayalım ve sütunları Türkçe'ye çevirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Genel Sıralama         Ülke  Skor  Kişi Başına Milli Gelir Puanı  \\\n",
      "0               2      Denmark  7600                         1383.0   \n",
      "1               3       Norway  7554                         1488.0   \n",
      "2               4      Iceland  7494                         1380.0   \n",
      "3               5  Netherlands  7488                         1396.0   \n",
      "4               6  Switzerland  7480                         1452.0   \n",
      "\n",
      "   Sosyal Destek Puanı  Sağlıklı Yaşam Beklentisi Puanı  \\\n",
      "0               1573.0                            0.996   \n",
      "1               1582.0                         1028.000   \n",
      "2               1624.0                         1026.000   \n",
      "3               1522.0                            0.999   \n",
      "4               1526.0                         1052.000   \n",
      "\n",
      "   Yaşam Tercihlerinde Özgürlük Puanı  Cömertlik Puanı  Yolsuzluk Algısı Puanı  \n",
      "0                               0.592            0.252                   0.410  \n",
      "1                               0.603            0.271                   0.341  \n",
      "2                               0.591            0.354                   0.118  \n",
      "3                               0.557            0.322                   0.298  \n",
      "4                               0.572            0.263                   0.343  \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df1 = xl.parse(0, skiprows=[0], names=['Genel Sıralama','Ülke', 'Skor', 'Kişi Başına Milli Gelir Puanı', \n",
    "                                       'Sosyal Destek Puanı', 'Sağlıklı Yaşam Beklentisi Puanı', \n",
    "                                       'Yaşam Tercihlerinde Özgürlük Puanı', 'Cömertlik Puanı', 'Yolsuzluk Algısı Puanı'])\n",
    "print(df1.head())\n",
    "print(type(df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SAS / Stata Dosyalarını Okuma\n",
    "\n",
    "SAS (Statistical Analysis System) gelişmiş bir veri analizi programıdır. Stata (Statistics + data) ise daha çok akademik sosyal bilimler araştırmalarında ve ekonometri amaçlı uygulamalarda kullanılan bir veri analizi programıdır. SAS dosyaları .sas7bdat uzantılıdır. Stata dosyaları ise .dta uzantılıdır. pandas kütüphanesi ile bu iki dosya formatını çalışma ortamından okuyabilmek mümkündür. Çalışma ortamımızda olan ve vergilerle ilgili analiz verilerini içeren tax.sas7bdat dosyasını yüklemeyele çalışalım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INC88  TAX88  INC89  TAX89\n",
      "0  9.215  1.643  9.518  2.125\n",
      "1  2.047  0.413  2.068  0.565\n",
      "2  9.989  1.752  9.992  2.221\n",
      "3  8.321  1.408  8.515  1.905\n",
      "4  4.588  0.838  4.389  0.943\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "with SAS7BDAT('tax.sas7bdat') as dosya:\n",
    "    df_sas = dosya.to_data_frame()\n",
    "    \n",
    "print(df_sas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aynı işlemi Stata (.dat uzantılı) veri seti için de uygulayalım. pd.read_stata() fonksiyonu işimizi görecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   inc88  tax88  inc89  tax89\n",
      "0  9.215  1.643  9.518  2.125\n",
      "1  2.047  0.413  2.068  0.565\n",
      "2  9.989  1.752  9.992  2.221\n",
      "3  8.321  1.408  8.515  1.905\n",
      "4  4.588  0.838  4.389  0.943\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_stata= pd.read_stata('tax.dta')\n",
    "print(df_stata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MATLAB Dosyalarını Okuma\n",
    "\n",
    "\"Matrix Laboratory\" olarak adlandırılan ve mühendislik uygulamalarında bir standart hesaplama dili olan MATLAB ticari paket programlama dilinde veriler .mat uzantılı dosyalar olarak saklanır. Örneğin Stanford Üniversitesi'nden araştırmacıların oluşturduğu araba veri setinin eğitim verilerinin .mat uzantılı versiyonunu scipy kütüphanesini kullanarak çalışma ortamımıza yükleyelim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sat Dec 14 14:13:07 2013', '__version__': '1.0', '__globals__': [], 'annotations': array([[(array([[39]], dtype=uint8), array([[116]], dtype=uint8), array([[569]], dtype=uint16), array([[375]], dtype=uint16), array([[14]], dtype=uint8), array(['00001.jpg'], dtype='<U9')),\n",
      "        (array([[36]], dtype=uint8), array([[116]], dtype=uint8), array([[868]], dtype=uint16), array([[587]], dtype=uint16), array([[3]], dtype=uint8), array(['00002.jpg'], dtype='<U9')),\n",
      "        (array([[85]], dtype=uint8), array([[109]], dtype=uint8), array([[601]], dtype=uint16), array([[381]], dtype=uint16), array([[91]], dtype=uint8), array(['00003.jpg'], dtype='<U9')),\n",
      "        ...,\n",
      "        (array([[26]], dtype=uint8), array([[246]], dtype=uint8), array([[660]], dtype=uint16), array([[449]], dtype=uint16), array([[163]], dtype=uint8), array(['08142.jpg'], dtype='<U9')),\n",
      "        (array([[78]], dtype=uint8), array([[526]], dtype=uint16), array([[1489]], dtype=uint16), array([[908]], dtype=uint16), array([[112]], dtype=uint8), array(['08143.jpg'], dtype='<U9')),\n",
      "        (array([[20]], dtype=uint8), array([[240]], dtype=uint8), array([[862]], dtype=uint16), array([[677]], dtype=uint16), array([[17]], dtype=uint8), array(['08144.jpg'], dtype='<U9'))]],\n",
      "      dtype=[('bbox_x1', 'O'), ('bbox_y1', 'O'), ('bbox_x2', 'O'), ('bbox_y2', 'O'), ('class', 'O'), ('fname', 'O')])}\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "dosya = 'cars_train_annos.mat'\n",
    "mat = scipy.io.loadmat(dosya)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".mat uzantılı dosyanın sözlük formatında (dict) yüklendiğini görüyoruz. Bu sözlüğün anahtarlarını inceleyelim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'annotations'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".mat dosyalarını okumak için `scipy.io.loadmat()` fonksiyonu, yazmak (kaydetmek) için de `scipy.io.savemat()` fonksiyonu kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Web Ortamından Veri Okuma\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web ortamındaki bağlantıları kullanarak da, Jupyter Notebook içerisine veri aktarımı yapmamız mümkündür. \n",
    "İstanbul Büyükşehir Belediyesi Açık Veri Portalı'ndan Ekim 2020 trafik verilerini kullanmak isteyelim.  (https://data.ibb.gov.tr/dataset/saatlik-trafik-yogunluk-veri-seti/resource/949d4a3b-91d2-4c56-b82f-4ef081e39c45)\n",
    "Bu sayfadaki verileri indirmeden, doğrudan bağlantı adresi alarak, veriyi çalışma ortamına eklememiz için `urllib.request` modülünün `urlretrieve` fonksiyonunu kullanabiliriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('traffic_density_202010.csv', <http.client.HTTPMessage at 0x1d701369988>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = 'https://data.ibb.gov.tr/dataset/3ee6d744-5da2-40c8-9cd6-0e3e41f1928f/resource/949d4a3b-91d2-4c56-b82f-4ef081e39c45/download/traffic_density_202010.csv'\n",
    "    \n",
    "urlretrieve(url, 'traffic_density_202010.csv') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DATE_TIME  LONGITUDE   LATITUDE GEOHASH  MINIMUM_SPEED  \\\n",
      "0  2020-10-04 01:00:00  28.866577  41.009216  sxk92c              6   \n",
      "1  2020-10-05 07:00:00  28.471069  41.135559  sxk4pb              9   \n",
      "2  2020-10-03 21:00:00  29.119263  41.031189  sxk9qt              6   \n",
      "3  2020-10-04 18:00:00  29.306030  41.113586  sxkcfu             54   \n",
      "4  2020-10-01 13:00:00  29.262085  40.877380  sxkb9c              6   \n",
      "\n",
      "   MAXIMUM_SPEED  AVERAGE_SPEED  NUMBER_OF_VEHICLES  \n",
      "0             68             30                  24  \n",
      "1             66             39                  19  \n",
      "2            122             70                 361  \n",
      "3            162            111                  13  \n",
      "4            108             48                 253  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('traffic_density_202010.csv', sep=',')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".csv dosyalar haricinde .xlsx dosyaları da bağlantıdan çekebilmek mümkündür. Bunun için pd.read_excel fonksiyonunu kullanarak, argüman oalrak bağlantı adresini kullanacağız. İstanbul Büyükşehir Belediyesi Açık Veri Portalı'nda sunulan İtfaiye Konum Verileri excel dosyasını (https://data.ibb.gov.tr/dataset/itfaiye-istasyonlari-konum-bilgileri/resource/c611b9a1-8a1a-44a9-816b-eb6dfcd37c42) kullanalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Metadata_TR', 'istasyonlar', 'müfrezeler'])\n"
     ]
    }
   ],
   "source": [
    "# pandas kütüphanesini yükleyelim. \n",
    "import pandas as pd\n",
    "\n",
    "# Bağlantı adresini oluşturulalım: url\n",
    "url = 'https://data.ibb.gov.tr/dataset/75cd7b09-dafb-41fa-90c9-9c7396a58700/resource/c611b9a1-8a1a-44a9-816b-eb6dfcd37c42/download/itfaiye-konum-verisi.xlsx'\n",
    "\n",
    "# Excel dosyasındaki tüm sayfaları okuyalım: xl\n",
    "xl = pd.read_excel(url, sheet_name=None)\n",
    "\n",
    "# Excel dosyasındaki tüm sayfa isimlerini ekrana verelim.\n",
    "print(xl.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  İstasyon Adı Bulunduğu İlçe  \\\n",
      "0                     Adalar İtfaiye İstasyonu         ADALAR   \n",
      "1  Akpınar Mahallesi Gönüllü İtfaiye İstasyonu     EYÜPSULTAN   \n",
      "2                Akşemsettin İtfaiye İstasyonu  GAZİOSMANPAŞA   \n",
      "3  Alacalı Mahallesi Gönüllü İtfaiye İstasyonu           ŞİLE   \n",
      "4                  Alibeyköy İtfaiye İstasyonu     EYÜPSULTAN   \n",
      "\n",
      "                 Koordinat  \n",
      "0  40.87172994,29.13762931  \n",
      "1  41.27821768,28.80994231  \n",
      "2     41.091980, 28.917401  \n",
      "3  41.18315865,29.45650909  \n",
      "4     41.079838, 28.937221  \n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Excel dosyasındaki ikinci çalışma sayfasının ilk beş satırını ekrana verelim (çalışma sayfası ismini kullanarak)\n",
    "print(xl['istasyonlar'].head())\n",
    "print(type(xl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
